a = 6
)
# Exemplo: Passando um vetor x qualquer de dados e obtendo o valor da função
# log-verosimilhança multiplicada por -1, uma vez que optim() minimiza:
log_lik(par = c(1.2, 1.3, 1), x = c(0.2, 0.2, 0.5, 0.65))
# Testando a função de verossimilhança log_lik():
amostra <- rweibull(n = 5000, shape = 2, scale = 3)
result <-
optim(
fn = log_lik,
par = c(2, 3, 1),
x = amostra,
method = "Nelder-Mead"
)
mc <-
function(M = 1e4L,
n = 250L,
par_true = c(2, 3, 1),
parallel = TRUE,
cluster) {
alpha <- par_true[1L]
beta <- par_true[2L]
a <- par_true[3L]
starts <- rep(1, length(par_true))
# Implementando a função de verossimilhança da weibull
log_lik <- function(par, x) {
alpha <- par[1L]
beta <- par[2L]
a <- par[3L]
- sum(log(pdf_exp_weibull(
x = x,
alpha = alpha,
beta = beta,
a = a
)))
}
# Tratamento de erro
myoptim <-
function(...)
tryCatch(
exp = optim(...),
error = function(e)
NA
)
# Uma única iteração de Monte-Carlo - MC:
mc_one_step <- function(i) {
# Não sei quantas vezes o repeat irá executar.
repeat {
cenario <- rweibull(n = n,
shape = alpha,
scale = beta)
result <- myoptim(fn = log_lik, par = starts, x = cenario)
if (!is.na(result) && result$convergence == 0)
break
} # Encontrando uma amostra adequada.
# Retornando as estimativas de máxima verossimilhança.
result$par
}
results_mc <-
pblapply(X = 1L:M, FUN = mc_one_step, cl = cl) %>%
unlist %>%
matrix(nrow = M,
ncol = length(par_true),
byrow = TRUE) %>%
as_tibble
colnames(results_mc) <- c("alpha", "beta", "a")
# Obtendo a média das estimativas de máxima verossimilhança por parâmetro:
mean_est <- apply(X = results_mc, MARGIN = 2L, FUN = mean)
bias <- mean_est - par_true
list(results_mc = results_mc,
mean_est = mean_est,
bias = bias)
}
cores <- getOption("mc.cores", 8L)
# Criando um cluster PSOCK:
cl <- makeCluster(cores, type = "PSOCK")
clusterExport(
cl = cl,
varlist = c("mc", "pdf_exp_weibull"),
envir = environment()
)
clusterSetRNGStream(cl = cl, iseed = 1)
system.time(result <-
mc(
M = 1000L,
n = 50,
par_true = c(2, 3, 1),
parallel = T,
cluster = cl
))
stopCluster(cl)
library(purrr)
library(numDeriv)
library(tibble)
library(parallel)
library(pbapply)
# Usando o conceito de closures na função exp_G().
exp_g <- function(G, ...) {
# Definindo uma função anônima. Funções anônimas são muito úteis na programação funcional.
function(x, ..., a) {
# Utilizano o operador dot-dot-dot.
numDeriv::grad(
func = function(x)
G(x = x, ...) ^ a,
x = x
)
}
}
# pdf() é a função Weibull de parâmetros alpha e beta.
cdf_weibull <-
function(x, alpha, beta, ...)
pweibull(q = x,
shape = alpha,
scale = beta,
...)
pdf_exp_weibull <- exp_g(G = cdf_weibull)
# Integrando a função pdf_exp_weibull():
integrate(
f = pdf_exp_weibull,
lower = 0,
upper = 100,
alpha = 1.2,
beta = 1.3,
a = 1
)
# Exemplo: implementando a função exp_weibull apenas declarando G que é a cdf weibull.
# Note também que a função exp_g() é tão flexível a ponto de permitir parâmetros de g
# sem mesmo saber quais são. Por exemplo, é possível definir o argumento log na função
# pdf_exp_weibull(). Veja:
pdf_exp_weibull <- exp_g(G = cdf_weibull)
pdf_exp_weibull(
x = 1,
alpha = 0.3,
beta = 1.2,
a = 1,
log = F
)
# Exemplo: vamos perceber o quanto exp_g permitirá a construção de funções flexíveis.
exp_beta <-
exp_g(
G = function(x, alpha, beta, ...)
pbeta(
q = x,
shape1 = alpha,
shape2 = beta,
...
)
)
# Integrando a função exp_beta():
integrate(
f = exp_beta,
lower = 0,
upper = 1,
alpha = 1.2,
beta = 1.3,
a = 6
)
# Exemplo: Passando um vetor x qualquer de dados e obtendo o valor da função
# log-verosimilhança multiplicada por -1, uma vez que optim() minimiza:
log_lik(par = c(1.2, 1.3, 1), x = c(0.2, 0.2, 0.5, 0.65))
# Testando a função de verossimilhança log_lik():
amostra <- rweibull(n = 5000, shape = 2, scale = 3)
result <-
optim(
fn = log_lik,
par = c(2, 3, 1),
x = amostra,
method = "Nelder-Mead"
)
mc <-
function(M = 1e4L,
n = 250L,
par_true = c(2, 3, 1),
parallel = TRUE,
cluster) {
alpha <- par_true[1L]
beta <- par_true[2L]
a <- par_true[3L]
starts <- rep(1, length(par_true))
# Implementando a função de verossimilhança da weibull
log_lik <- function(par, x) {
alpha <- par[1L]
beta <- par[2L]
a <- par[3L]
- sum(log(pdf_exp_weibull(
x = x,
alpha = alpha,
beta = beta,
a = a
)))
}
# Tratamento de erro
myoptim <-
function(...)
tryCatch(
exp = optim(...),
error = function(e)
NA
)
# Uma única iteração de Monte-Carlo - MC:
mc_one_step <- function(i) {
# Não sei quantas vezes o repeat irá executar.
repeat {
cenario <- rweibull(n = n,
shape = alpha,
scale = beta)
result <- myoptim(fn = log_lik, par = starts, x = cenario)
if (!is.na(result) && result$convergence == 0)
break
} # Encontrando uma amostra adequada.
# Retornando as estimativas de máxima verossimilhança.
result$par
}
results_mc <-
pblapply(X = 1L:M, FUN = mc_one_step, cl = cl) %>%
unlist %>%
matrix(nrow = M,
ncol = length(par_true),
byrow = TRUE) %>%
as_tibble
colnames(results_mc) <- c("alpha", "beta", "a")
# Obtendo a média das estimativas de máxima verossimilhança por parâmetro:
mean_est <- apply(X = results_mc, MARGIN = 2L, FUN = mean)
bias <- mean_est - par_true
list(results_mc = results_mc,
mean_est = mean_est,
bias = bias)
}
cores <- getOption("mc.cores", 8L)
# Criando um cluster PSOCK:
cl <- makeCluster(cores, type = "PSOCK")
clusterExport(
cl = cl,
varlist = c("mc", "pdf_exp_weibull"),
envir = environment()
)
clusterSetRNGStream(cl = cl, iseed = 1)
system.time(result <-
mc(
M = 1000L,
n = 50,
par_true = c(2, 3, 1),
parallel = T,
cluster = cl
))
stopCluster(cl)
library(purrr)
library(numDeriv)
library(tibble)
library(parallel)
library(pbapply)
# Usando o conceito de closures na função exp_G().
exp_g <- function(G, ...) {
# Definindo uma função anônima. Funções anônimas são muito úteis na programação funcional.
function(x, ..., a) {
# Utilizano o operador dot-dot-dot.
numDeriv::grad(
func = function(x)
G(x = x, ...) ^ a,
x = x
)
}
}
# pdf() é a função Weibull de parâmetros alpha e beta.
cdf_weibull <-
function(x, alpha, beta, ...)
pweibull(q = x,
shape = alpha,
scale = beta,
...)
pdf_exp_weibull <- exp_g(G = cdf_weibull)
# Integrando a função pdf_exp_weibull():
integrate(
f = pdf_exp_weibull,
lower = 0,
upper = 100,
alpha = 1.2,
beta = 1.3,
a = 1
)
# Exemplo: implementando a função exp_weibull apenas declarando G que é a cdf weibull.
# Note também que a função exp_g() é tão flexível a ponto de permitir parâmetros de g
# sem mesmo saber quais são. Por exemplo, é possível definir o argumento log na função
# pdf_exp_weibull(). Veja:
pdf_exp_weibull <- exp_g(G = cdf_weibull)
pdf_exp_weibull(
x = 1,
alpha = 0.3,
beta = 1.2,
a = 1,
log = F
)
# Exemplo: vamos perceber o quanto exp_g permitirá a construção de funções flexíveis.
exp_beta <-
exp_g(
G = function(x, alpha, beta, ...)
pbeta(
q = x,
shape1 = alpha,
shape2 = beta,
...
)
)
# Integrando a função exp_beta():
integrate(
f = exp_beta,
lower = 0,
upper = 1,
alpha = 1.2,
beta = 1.3,
a = 6
)
# Exemplo: Passando um vetor x qualquer de dados e obtendo o valor da função
# log-verosimilhança multiplicada por -1, uma vez que optim() minimiza:
log_lik(par = c(1.2, 1.3, 1), x = c(0.2, 0.2, 0.5, 0.65))
# Testando a função de verossimilhança log_lik():
amostra <- rweibull(n = 5000, shape = 2, scale = 3)
result <-
optim(
fn = log_lik,
par = c(2, 3, 1),
x = amostra,
method = "Nelder-Mead"
)
mc <-
function(M = 1e4L,
n = 250L,
par_true = c(2, 3, 1),
parallel = TRUE,
cluster) {
alpha <- par_true[1L]
beta <- par_true[2L]
a <- par_true[3L]
starts <- rep(1, length(par_true))
# Implementando a função de verossimilhança da weibull
log_lik <- function(par, x) {
alpha <- par[1L]
beta <- par[2L]
a <- par[3L]
- sum(log(pdf_exp_weibull(
x = x,
alpha = alpha,
beta = beta,
a = a
)))
}
# Tratamento de erro
myoptim <-
function(...)
tryCatch(
exp = optim(...),
error = function(e)
NA
)
# Uma única iteração de Monte-Carlo - MC:
mc_one_step <- function(i) {
# Não sei quantas vezes o repeat irá executar.
repeat {
cenario <- rweibull(n = n,
shape = alpha,
scale = beta)
result <- myoptim(fn = log_lik, par = starts, x = cenario)
if (!is.na(result) && result$convergence == 0)
break
} # Encontrando uma amostra adequada.
# Retornando as estimativas de máxima verossimilhança.
result$par
}
results_mc <-
pblapply(X = 1L:M, FUN = mc_one_step, cl = cl) %>%
unlist %>%
matrix(nrow = M,
ncol = length(par_true),
byrow = TRUE) %>%
as_tibble
colnames(results_mc) <- c("alpha", "beta", "a")
# Obtendo a média das estimativas de máxima verossimilhança por parâmetro:
mean_est <- apply(X = results_mc, MARGIN = 2L, FUN = mean)
bias <- mean_est - par_true
list(results_mc = results_mc,
mean_est = mean_est,
bias = bias)
}
cores <- getOption("mc.cores", 1L)
# Criando um cluster PSOCK:
cl <- makeCluster(cores, type = "PSOCK")
clusterExport(
cl = cl,
varlist = c("mc", "pdf_exp_weibull"),
envir = environment()
)
clusterSetRNGStream(cl = cl, iseed = 1)
system.time(result <-
mc(
M = 1000L,
n = 50,
par_true = c(2, 3, 1),
parallel = T,
cluster = cl
))
stopCluster(cl)
exists("mcfork", mode="function")
library(numDeriv)
library(parallel)
library(pbmcapply)
library(magrittr)
# Usando conceito de closures para implementar a função exp_g() de forma
# genérica.
exp_g <- function(G, ...) {
function(x, ..., a) {
grad(fun = function(x) G(x, ...) ^ a, x = x)
}
}
cdf_weibull <- function(x, alpha, beta, ...)
pweibull(q = x, shape = alpha, scale= beta, ...)
# Construindo a função densidade de probabilidade da Exp-Weibull.
pdf_exp_weibull <- exp_g(G = cdf_weibull)
pdf_exp_weibull(x = 1.2, alpha = 1, beta = 2, a = 1)
# Iniciando a implementação da simulação de MC ----------------------------
mc <- function(M = 1e3L, n = 100L, par_true = c(2, 3, 1), cl = cl) {
alpha <- par_true[1L]
beta <- par_true[2L]
a <- par_true[3L]
starts <- rep(1, length(par_true))
# Implementando a função log-verossimilhança da Exp-Weibull:
log_lik <- function(par, x) {
alpha <- par[1L]
beta <- par[2L]
a <- par[3L]
-sum(log(pdf_exp_weibull(x = x, alpha = alpha, beta = beta, a = a)))
}
myoptim <- function(...)
tryCatch(
expr = optim(...),
error = function(e)
NA
)
# Uma única iteração de Monte-Carlo - MC:
mc_one_step <- function(i){
repeat{
cenario <- rweibull(n = n, shape = alpha, scale = beta)
result <- myoptim(fn = log_lik, par = starts, x = cenario)
if(!is.na(result) && result$convergence == 0)
break
}
result$par # Estimativas de máxima verossimilhança.
}
result_mc <-
pbmclapply(X = 1L:M, FUN = mc_one_step, mc.cores = detectCores()) %>%
unlist %>%
matrix(ncol = length(par_true), nrow = M, byrow = TRUE)
colnames(result_mc) <- c("alpha", "beta", "a")
mean_mc <- apply(X = result_mc, MARGIN = 2L, FUN = mean) # Média das estimativas
bias <- mean_mc - par_true # Víes
list(result_mc = result_mc, mean_mc = mean_mc, bias = bias)
}
system.time(result <- mc(M = 1000, n = 100, par_true = c(2, 3, 1), cl = cl))
library(numDeriv)
library(parallel)
library(pbmcapply)
library(magrittr)
# Usando conceito de closures para implementar a função exp_g() de forma
# genérica.
exp_g <- function(G, ...) {
function(x, ..., a) {
grad(fun = function(x) G(x, ...) ^ a, x = x)
}
}
cdf_weibull <- function(x, alpha, beta, ...)
pweibull(q = x, shape = alpha, scale= beta, ...)
# Construindo a função densidade de probabilidade da Exp-Weibull.
pdf_exp_weibull <- exp_g(G = cdf_weibull)
pdf_exp_weibull(x = 1.2, alpha = 1, beta = 2, a = 1)
# Iniciando a implementação da simulação de MC ----------------------------
mc <- function(M = 1e3L, n = 100L, par_true = c(2, 3, 1), cl = cl) {
alpha <- par_true[1L]
beta <- par_true[2L]
a <- par_true[3L]
starts <- rep(1, length(par_true))
# Implementando a função log-verossimilhança da Exp-Weibull:
log_lik <- function(par, x) {
alpha <- par[1L]
beta <- par[2L]
a <- par[3L]
-sum(log(pdf_exp_weibull(x = x, alpha = alpha, beta = beta, a = a)))
}
myoptim <- function(...)
tryCatch(
expr = optim(...),
error = function(e)
NA
)
# Uma única iteração de Monte-Carlo - MC:
mc_one_step <- function(i){
repeat{
cenario <- rweibull(n = n, shape = alpha, scale = beta)
result <- myoptim(fn = log_lik, par = starts, x = cenario)
if(!is.na(result) && result$convergence == 0)
break
}
result$par # Estimativas de máxima verossimilhança.
}
result_mc <-
pbmclapply(X = 1L:M, FUN = mc_one_step, mc.cores = detectCores()) %>%
unlist %>%
matrix(ncol = length(par_true), nrow = M, byrow = TRUE)
colnames(result_mc) <- c("alpha", "beta", "a")
mean_mc <- apply(X = result_mc, MARGIN = 2L, FUN = mean) # Média das estimativas
bias <- mean_mc - par_true # Víes
list(result_mc = result_mc, mean_mc = mean_mc, bias = bias)
}
system.time(result <- mc(M = 1000, n = 100, par_true = c(2, 3, 1), cl = cl))
